# RecallLens: AI-Powered Visual Memory for Remote Work & Learning

> Turn any meeting, lecture, or tutorial into a **searchable, multimodal knowledge base**â€”with deep AI insight into both speech and visuals.

---

## âœ¨ Features

- Upload or connect remote meeting/lecture recordings
- AI-generated summaries for every segment
- Visual timeline with slide/diagram detection
- â€œAsk the Meetingâ€: Natural language Q&A (audio + visual context)
- Tag and filter by topics, speakers, slides, or screen shares
- Export highlights and action items
- Secure, scalable, and privacy-first

---

## ğŸš€ Quick Start

1. **Clone the repo**
2. **Install backend and frontend dependencies**
3. **Set up HuggingFace keys and auth config**
4. **Run backend and frontend locally (Docker-compose or Railway)**
5. **Connect your Zoom/Meet/YouTube account or upload a file**
6. **Open `localhost:3000` to use RecallLens!**

---

## ğŸ—ï¸ System Architecture

![Architecture Diagram](docs/architecture.png)

### **Components**
- **Frontend:** React (Next.js) + TailwindCSS
- **Backend:** FastAPI + Celery + PostgreSQL + S3 + Elasticsearch
- **AI Pipelines:**  
  - Speech-to-text  
  - Video/image-to-text  
  - Visual Q&A  
  - Video summarization/classification
- **Integrations:** Zoom, YouTube, LMS APIs
- **Auth:** Auth0/Firebase

---

## ğŸ”‘ Key AI Tasks (HuggingFace)

| Task                   | Example Model(s)           | Purpose                                         |
|------------------------|----------------------------|-------------------------------------------------|
| Speech-to-Text         | whisper-large              | Transcribe meetings/lectures                    |
| Video-Text-to-Text     | blip2, flamingo            | Summarize video segments                        |
| Visual QA              | OFA, blip2                 | Answer â€œwhatâ€™s on screenâ€ queries               |
| Image-to-Text          | Donut, pix2struct          | Describe slides, diagrams                       |
| Doc QA                 | layoutLMv3                 | Extract from shared documents                   |
| Video Classification   | timesformer, mvit          | Tag â€œpresentationâ€, â€œQ&Aâ€, â€œdiscussionâ€, etc.   |

---

## ğŸ’¡ Why RecallLens?

- **Save hours** by jumping to the exact moment you need.
- **Donâ€™t miss key visuals:** Find slides, diagrams, or shared docs instantly.
- **Better remote learning:** Retrieve context-rich moments from any lecture or training.

---

## ğŸ› ï¸ Tech Stack

| Layer      | Technology                                |
|------------|-------------------------------------------|
| Frontend   | React (Next.js), TailwindCSS              |
| Backend    | FastAPI, Celery, PostgreSQL               |
| ML         | HuggingFace Transformers/Inference API    |
| Video      | FFmpeg, OpenCV                            |
| Storage    | S3 or Cloudinary (snapshots/frames)       |
| Search     | Elasticsearch or Weaviate                 |
| Auth       | Auth0/Firebase                            |
| Deploy     | Docker, K8s, AWS/Railway                  |
| Integrate  | Zoom/Meet/YouTube APIs                    |

---

## ğŸ“ˆ Portfolio Value

- Multimodal AI integration (audio, video, images)
- Scalable cloud-native architecture
- Asynchronous, resilient processing
- Real UX for real pain points (remote work, e-learning)
- SaaS/product potential (Notion, Slack, enterprise integrations)

---

## ğŸ¤– Getting Started (Dev Notes)

- Use provided scripts for local demo with sample videos (public datasets listed below)
- Configure HuggingFace and API keys in `.env.example`
- (See `CONTRIBUTING.md` for dev setup and architecture details)

---

## ğŸ—ƒï¸ Useful Datasets & APIs

- [AMR Meeting Corpus](https://catalog.ldc.upenn.edu/LDC2004T12)
- [YouTube-8M](https://research.google.com/youtube8m/)
- [ICCV-VQA](https://www.robots.ox.ac.uk/~vgg/data/vqa/)
- [Zoom API](https://marketplace.zoom.us/docs/api-reference/zoom-api/)
- [Google Meet API](https://developers.google.com/calendar/api/v3/reference/)

---

## ğŸ“¢ Demo & Screenshots

*(Coming soon: GIFs and walkthroughs!)*

---

## ğŸ† License & Contact

MIT License.  
Questions? PRs welcome!
